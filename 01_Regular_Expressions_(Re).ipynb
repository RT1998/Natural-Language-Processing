{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Regular Expressions (Regex) for Text Preprocessing\n",
        "\n",
        "## What are Regular Expressions (Regex)?\n",
        "\n",
        "Regular expressions (often abbreviated as **regex**) are a powerful tool for text processing and pattern matching.\n",
        "\n",
        "They provide a way to specify a search pattern for text, which can be used to find, extract, and manipulate data in a string.\n",
        "\n",
        "Regex is commonly used in text preprocessing tasks, such as cleaning, extracting information, and transforming text into a format suitable for further analysis.\n",
        "\n",
        "## Why Use Regex in Text Processing?\n",
        "\n",
        "When working with natural language processing (NLP), a large part of the process involves extracting, cleaning, and transforming raw text data. Regex provides an efficient and flexible way to:\n",
        "\n",
        "- Search for specific patterns (e.g., email addresses, phone numbers, dates).\n",
        "- Replace parts of text (e.g., remove unwanted characters, standardize formats).\n",
        "- Split or tokenize text based on specific rules.\n",
        "- Extract and manipulate data from structured or unstructured text sources.\n",
        "\n",
        "In Python, the `re` module provides the tools to work with regular expressions. The module includes several functions that make it easy to perform search, match, and replace operations within a string."
      ],
      "metadata": {
        "id": "wOoow6fmf4XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\" Hello! My name is Anonymous. I am learning Natural Language Processing (NLP) with Python.\n",
        "anonymous.123@example.com for more details or call me at 134-122-3440. Yesterday, I was reading about how **Pythonista**\n",
        "is a term used for enthusiasts who love Python.\"\"\"\n",
        "\n",
        "print(sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hPDlYN7f6EB",
        "outputId": "1494a07e-cc0f-4a21-eddc-c87f949351a2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hello! My name is Anonymous. I am learning Natural Language Processing (NLP) with Python.\n",
            "anonymous.123@example.com for more details or call me at 134-122-3440. Yesterday, I was reading about how **Pythonista** \n",
            "is a term used for enthusiasts who love Python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "rV8EUQnzgVk-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Matching a Literal String\n",
        "\n",
        "pattern = r\"Python\"\n",
        "match = re.search(pattern, sample_text)\n",
        "\n",
        "if match:\n",
        "    print(\"Found:\", match.group())\n",
        "    print(match.group())\n",
        "else:\n",
        "    print(\"No match found.\")\n",
        "\n",
        "print('=============================')\n",
        "\n",
        "pattern = r\"Demo\"\n",
        "match = re.search(pattern, sample_text)\n",
        "\n",
        "if match:\n",
        "    print(\"Found:\", match.group())\n",
        "    print(match.group())\n",
        "else:\n",
        "    print(\"No match found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O30EP_zgM8Y",
        "outputId": "39744f54-daab-4a6c-d8ef-bdd66877c830"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found: Python\n",
            "Python\n",
            "=============================\n",
            "No match found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Matching Digits\n",
        "# Pattern to match any digit (0-9)\n",
        "pattern = r\"\\d\"\n",
        "digits = re.findall(pattern, sample_text)\n",
        "\n",
        "print(\"Digits found:\", digits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8Gn9JErg6c0",
        "outputId": "2cdbe705-2f14-410c-e031-5652014137bf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digits found: ['1', '2', '3', '1', '3', '4', '1', '2', '2', '3', '4', '4', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Extracting Email Addresses\n",
        "# Pattern to match email addresses\n",
        "pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
        "emails = re.findall(pattern, sample_text)\n",
        "\n",
        "print(\"Emails found:\", emails)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuSohCT8hCSu",
        "outputId": "3c048517-e06f-4c42-b0fe-c385e363d24f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emails found: ['anonymous.123@example.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4: Extracting Phone Numbers\n",
        "# Pattern to match phone numbers (e.g., 123-456-7890)\n",
        "pattern = r\"\\d{3}-\\d{3}-\\d{4}\"\n",
        "phone_numbers = re.findall(pattern, sample_text)\n",
        "\n",
        "print(\"Phone numbers found:\", phone_numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8THpeFQ5hIHS",
        "outputId": "300f1d5e-5693-4a75-eb95-8259f2f74a1c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phone numbers found: ['134-122-3440']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 5: Removing Punctuation\n",
        "# Pattern to remove punctuation (anything that's not a word character or space)\n",
        "pattern = r\"[^\\w\\s]\"\n",
        "cleaned_text = re.sub(pattern, \"\", sample_text)\n",
        "\n",
        "print(\"Text after removing punctuation:\")\n",
        "print(cleaned_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tz12_mvhy1T",
        "outputId": "f76bee67-6f1b-42de-ea2f-0b769d7368ab"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text after removing punctuation:\n",
            " Hello My name is Anonymous I am learning Natural Language Processing NLP with Python\n",
            "anonymous123examplecom for more details or call me at 1341223440 Yesterday I was reading about how Pythonista \n",
            "is a term used for enthusiasts who love Python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 6: Replacing Text\n",
        "pattern = r\"NLP\"\n",
        "replacement = \"Natural Language Processing\"\n",
        "replaced_text = re.sub(pattern, replacement, sample_text)\n",
        "\n",
        "print(\"Text after replacement:\")\n",
        "print(replaced_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNR6ugcph6Dx",
        "outputId": "275c4025-c471-4095-f9db-f280dc62742a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text after replacement:\n",
            " Hello! My name is Anonymous. I am learning Natural Language Processing (Natural Language Processing) with Python.\n",
            "anonymous.123@example.com for more details or call me at 134-122-3440. Yesterday, I was reading about how **Pythonista** \n",
            "is a term used for enthusiasts who love Python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 7: Matching Multiple Words/Phrases\n",
        "# Pattern to match either 'Python' or 'NLP'\n",
        "pattern = r\"Python|NLP\"\n",
        "matches = re.findall(pattern, sample_text)\n",
        "\n",
        "print(\"Matches for 'Python' or 'NLP':\", matches)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjC4yNxPiA8T",
        "outputId": "6f72501a-b211-4478-9730-1a7e19622dd4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches for 'Python' or 'NLP': ['NLP', 'Python', 'Python', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 8: Matching Word Boundaries\n",
        "# Pattern to match the word 'Python' as a whole word (not part of another word)\n",
        "pattern = r\"\\bPython\\b\"\n",
        "matches = re.findall(pattern, sample_text)\n",
        "\n",
        "print(\"Matches for the word 'Python':\", matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnyIz0K3iN6e",
        "outputId": "9b6deac4-b5d5-48d1-8060-3fb7c024f4ed"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches for the word 'Python': ['Python', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 9: Matching Specific Character Classes\n",
        "# Pattern to match any word starting with a capital letter\n",
        "pattern = r\"\\b[A-Z][a-z]*\\b\"\n",
        "capitalized_words = re.findall(pattern, sample_text)\n",
        "\n",
        "print(\"Capitalized words found:\", capitalized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkEbeLtKi2tQ",
        "outputId": "640ce8c1-1f9c-4033-e74c-4db7ee5d8448"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capitalized words found: ['Hello', 'My', 'Anonymous', 'I', 'Natural', 'Language', 'Processing', 'Python', 'Yesterday', 'I', 'Pythonista', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 10: Counting Occurrences of a Pattern\n",
        "pattern = r\"Python\"\n",
        "count = len(re.findall(pattern, sample_text))\n",
        "\n",
        "print(\"Number of occurrences of 'NLP':\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIQtsCyti9Af",
        "outputId": "44ace64a-c77a-456c-8129-2040432b496d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of occurrences of 'NLP': 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve order number\n",
        "\n",
        "sample_text='My order 412889912 is having an issue, I was charged 300$ when online it says 280$'\n",
        "pattern = 'order[^\\d]*(\\d*)'\n",
        "matches = re.findall(pattern, sample_text)\n",
        "\n",
        "print('order information/number: ', matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIg9tFRUoGJ1",
        "outputId": "3cc6829f-75a9-4821-db93-f47fd05c2443"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "order information/number:  ['412889912']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract specific information\n",
        "sample_text='''\n",
        "Born\tElon Reeve Musk\n",
        "June 28, 1971 (age 50)\n",
        "Pretoria, Transvaal, South Africa\n",
        "Citizenship\n",
        "South Africa (1971â€“present)\n",
        "Canada (1971â€“present)\n",
        "United States (2002â€“present)\n",
        "Education\tUniversity of Pennsylvania (BS, BA)\n",
        "Title\n",
        "Founder, CEO and Chief Engineer of SpaceX\n",
        "CEO and product architect of Tesla, Inc.\n",
        "Founder of The Boring Company and X.com (now part of PayPal)\n",
        "Co-founder of Neuralink, OpenAI, and Zip2\n",
        "Spouse(s)\n",
        "Justine Wilson\n",
        "â€‹\n",
        "â€‹(m. 2000; div. 2008)â€‹\n",
        "Talulah Riley\n",
        "â€‹\n",
        "â€‹(m. 2010; div. 2012)â€‹\n",
        "â€‹\n",
        "â€‹(m. 2013; div. 2016)\n",
        "'''"
      ],
      "metadata": {
        "id": "1GdoNJmgpddI"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age = re.findall('age (\\d+)', sample_text)[0]\n",
        "full_name = re.findall('Born(.*)\\n', sample_text)[0]\n",
        "birth_date = re.findall('Born.*\\n(.*)\\(age', sample_text)[0]\n",
        "birth_place = re.findall('\\(age.*\\n(.*)', sample_text)[0]\n",
        "\n",
        "print ({\n",
        "        'age': age,\n",
        "        'name': full_name,\n",
        "        'birth_date': birth_date,\n",
        "        'birth_place': birth_place\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plM8MVw9poWr",
        "outputId": "4c6dd964-1685-4c6d-dfe9-7ce02524e7f1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'age': '50', 'name': '\\tElon Reeve Musk', 'birth_date': 'June 28, 1971 ', 'birth_place': 'Pretoria, Transvaal, South Africa'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\n",
        "tweet = \"loving the new features of #Python @anonymous https://python.org ðŸ˜ŠðŸš€\"\n",
        "\n",
        "# Regex pattern to match words, hashtags, mentions, URLs, and emojis\n",
        "pattern = r\"\\b(?:https?://\\S+|www\\.\\S+|\\#\\w+|\\@\\w+|[a-zA-Z0-9]+(?:[-']\\w+)*|\\w+|[^\\w\\s])\\b\"\n",
        "tokens = re.findall(pattern, tweet)\n",
        "\n",
        "# Displaying the tokens\n",
        "print(\"Tokens:\", tokens)\n"
      ],
      "metadata": {
        "id": "5BcaDGAVnldm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello, world! I'm learning Python. #Excited\"\n",
        "\n",
        "# Regex pattern to tokenize the text (split by any non-word characters)\n",
        "pattern = r\"\\w+\"\n",
        "tokens = re.findall(pattern, text)\n",
        "\n",
        "# Displaying the tokens\n",
        "print(\"Tokens:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k82H4CKm3e_",
        "outputId": "390b0407-395d-4699-d5df-a80193b0c934"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Hello', 'world', 'I', 'm', 'learning', 'Python', 'Excited']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"loving the new features of #Python @anonymous https://python.org ðŸ˜ŠðŸš€\"\n",
        "\n",
        "# Regex pattern to match words, hashtags, mentions, URLs, and emojis\n",
        "pattern = r\"\\b(?:https?://\\S+|www\\.\\S+|\\#\\w+|\\@\\w+|[a-zA-Z0-9]+(?:[-']\\w+)*|\\w+|[^\\w\\s])\\b\"\n",
        "tokens = re.findall(pattern, tweet)\n",
        "\n",
        "# Displaying the tokens\n",
        "print(\"Tokens:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umlPf246jtck",
        "outputId": "4059cbde-5040-4bcf-82b7-32a2d83e26d6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['loving', 'the', 'new', 'features', 'of', 'Python', 'anonymous', 'https://python.org']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **https?://\\S+**: Matches URLs starting with http:// or https://.\n",
        "* **www\\.\\S+**: Matches URLs starting with www.\n",
        "* **\\#\\w+**: Matches hashtags (e.g., #Python).\n",
        "* **\\@\\w+**: Matches mentions (e.g., @john_doe).\n",
        "* [a-zA-Z0-9]+(?:[-']\\w+)*: Matches words that may contain hyphens or apostrophes.\n",
        "* **[^\\w\\s]**: Matches punctuation or special characters."
      ],
      "metadata": {
        "id": "FTQiDBEbkOTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regex to remove emojis\n",
        "emoji_pattern = r\"[^\\w\\s,.'!&-]\"  # Matches any non-word character excluding punctuation\n",
        "text_with_emojis = \"I love Python! ðŸš€ðŸ”¥ @PythonDev #Python\"\n",
        "\n",
        "# Removing emojis\n",
        "cleaned_text = re.sub(emoji_pattern, \"\", text_with_emojis)\n",
        "\n",
        "print(\"Text without emojis:\", cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV6le6W1lcm6",
        "outputId": "d3dd02ce-b331-4617-e535-8e809aedbbc4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text without emojis: I love Python!  PythonDev Python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I have a few cats. The dogs were playing.\"\n",
        "\n",
        "# Regex pattern for basic plural to singular (e.g., cats -> cat, dogs -> dog)\n",
        "pattern_plural = r\"(\\w+)(s)\\b\"\n",
        "text_singular = re.sub(pattern_plural, r\"\\1\", text)\n",
        "\n",
        "# Regex pattern for basic verb forms (e.g., were, is, am, are, was, were, been , being -> be)\n",
        "pattern_verb = r\"(were|is|am|are|was|were|been|being)\\b\"\n",
        "text_lemmatized = re.sub(pattern_verb, \"be\", text_singular)\n",
        "\n",
        "print(\"Text after basic lemmatization:\", text_lemmatized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwjQEmjZlBN6",
        "outputId": "81be19d0-d862-4494-9883-b58dd1206522"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text after basic lemmatization: I have a few cat. The dog be playing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"Check out my blog: https://example.com! @john_doe #Python #AI\"\n",
        "\n",
        "# Regex patterns to extract hashtags, mentions, and URLs\n",
        "hashtag_pattern = r\"\\#\\w+\"\n",
        "mention_pattern = r\"\\@\\w+\"\n",
        "url_pattern = r\"https?://[^\\s]+\"\n",
        "\n",
        "# Extracting hashtags, mentions, and URLs\n",
        "hashtags = re.findall(hashtag_pattern, tweet)\n",
        "mentions = re.findall(mention_pattern, tweet)\n",
        "urls = re.findall(url_pattern, tweet)\n",
        "\n",
        "print(\"Hashtags:\", hashtags)\n",
        "print(\"Mentions:\", mentions)\n",
        "print(\"URLs:\", urls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od_bM_pIlIJl",
        "outputId": "742a9b55-4b37-438f-c7eb-24f39a2a3129"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hashtags: ['#Python', '#AI']\n",
            "Mentions: ['@john_doe']\n",
            "URLs: ['https://example.com!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing stop words\n",
        "# List of common stopwords\n",
        "stopwords = [\"the\", \"and\", \"is\", \"in\", \"to\", \"for\", \"on\"]\n",
        "\n",
        "text = \"Python is great for data analysis and machine learning.\"\n",
        "\n",
        "# Regex pattern for stopwords\n",
        "stopword_pattern = r\"\\b(?:{})\\b\".format(\"|\".join(stopwords))\n",
        "cleaned_text = re.sub(stopword_pattern, \"\", text)\n",
        "\n",
        "cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
        "print(\"Text without stopwords:\", cleaned_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0-P0lXHliZm",
        "outputId": "feb061be-bff9-420c-991c-d1f97f737aae"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text without stopwords: Python great data analysis machine learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom tokenization: Preserve punctuation and emojis\n",
        "pattern = r\"([^\\w\\s]+|[\\u2000-\\u3300]+|\\w+)\"\n",
        "tweet = \"I love Python! ðŸš€ðŸ”¥ #Python\"\n",
        "\n",
        "tokens = re.findall(pattern, tweet)\n",
        "print(\"Custom tokens:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obgr_Oh6mrr9",
        "outputId": "5cb18123-0131-48bc-c376-83154b599606"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom tokens: ['I', 'love', 'Python', '!', 'ðŸš€ðŸ”¥', '#', 'Python']\n"
          ]
        }
      ]
    }
  ]
}